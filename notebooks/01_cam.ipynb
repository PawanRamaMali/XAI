{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load pre-trained ResNet50 model\n",
    "# This model is trained on ImageNet and can be used for feature extraction\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Global variable to store activations from the target layer\n",
    "activations = None\n",
    "\n",
    "# Hook function to capture activations from the target layer\n",
    "def forward_hook(module, input, output):\n",
    "    global activations\n",
    "    activations = output  # Save the output feature maps\n",
    "\n",
    "# Register hook on the last convolutional layer of ResNet50\n",
    "target_layer = model.layer4[2].conv3  # This is the last convolutional layer\n",
    "target_layer.register_forward_hook(forward_hook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the image:\n",
    "    - Resizes it to 224x224 (required for ResNet50)\n",
    "    - Converts it to a PyTorch tensor\n",
    "    - Normalizes using ImageNet mean and standard deviation\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert('RGB')  # Ensure it's in RGB format\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize image to fit ResNet50 input size\n",
    "        transforms.ToTensor(),  # Convert image to tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize as per ImageNet\n",
    "    ])\n",
    "    return transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Function to compute the Class Activation Map (CAM)\n",
    "def compute_cam(img_path):\n",
    "    \"\"\"\n",
    "    - Passes the image through the model.\n",
    "    - Extracts the activation map from the last convolutional layer.\n",
    "    - Uses the predicted class to generate a heatmap.\n",
    "    \"\"\"\n",
    "    img = preprocess_image(img_path)\n",
    "    output = model(img)  # Forward pass\n",
    "\n",
    "    # Get the predicted class (highest score)\n",
    "    class_idx = torch.argmax(output).item()\n",
    "    \n",
    "    # Extract activation map for the predicted class\n",
    "    class_activation = activations[0, class_idx].detach().numpy()\n",
    "    \n",
    "    # Apply ReLU (only keep positive values)\n",
    "    heatmap = np.maximum(class_activation, 0)  \n",
    "\n",
    "    # Normalize the heatmap (scale values between 0 and 1)\n",
    "    heatmap /= np.max(heatmap)  \n",
    "\n",
    "    return heatmap, class_idx  # Return heatmap and predicted class index\n",
    "\n",
    "# Function to overlay the heatmap on the original image\n",
    "def overlay_heatmap(img_path, heatmap):\n",
    "    \"\"\"\n",
    "    - Resizes the heatmap to match the original image size.\n",
    "    - Applies a color map to highlight important regions.\n",
    "    - Blends the heatmap with the original image.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(img_path)  # Read the original image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct display\n",
    "    \n",
    "    # Resize heatmap to match image size\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Convert heatmap to 8-bit (0-255)\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Apply color map for better visualization\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Blend original image and heatmap\n",
    "    overlay = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    return img, heatmap, overlay\n",
    "\n",
    "# Function to display results using Matplotlib\n",
    "def display_results(img_path, heatmap, overlay, class_idx):\n",
    "    \"\"\"\n",
    "    - Displays the original image, activation heatmap, and CAM overlay.\n",
    "    - Uses Matplotlib for visualization.\n",
    "    \"\"\"\n",
    "    # Load original image\n",
    "    original = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    # Create a subplot with 3 images\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(heatmap, cmap=\"jet\")\n",
    "    axes[1].set_title(f\"Activation Map (Class {class_idx})\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title(\"CAM Overlay\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load a medical image for demonstration (e.g., chest X-ray)\n",
    "img_path = \"chest_xray.jpg\"  # Replace with actual medical image path\n",
    "\n",
    "# Generate CAM heatmap and overlay\n",
    "heatmap, class_idx = compute_cam(img_path)\n",
    "original_img, heatmap_img, overlay_img = overlay_heatmap(img_path, heatmap)\n",
    "\n",
    "# Display the results\n",
    "display_results(img_path, heatmap_img, overlay_img, class_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
